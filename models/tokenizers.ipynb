{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Downloading Tokenizers\n\nThis notebook allows me to download the 2 LLM tokenizers that I need.","metadata":{}},{"cell_type":"code","source":"# Importing libraries\nfrom transformers import AutoTokenizer","metadata":{"execution":{"iopub.status.busy":"2024-02-04T18:51:34.763853Z","iopub.execute_input":"2024-02-04T18:51:34.764250Z","iopub.status.idle":"2024-02-04T18:51:40.653847Z","shell.execute_reply.started":"2024-02-04T18:51:34.764224Z","shell.execute_reply":"2024-02-04T18:51:40.652585Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Getting the tokenizers\nbert_tokenizer = AutoTokenizer.from_pretrained('roberta-base')\ndistil_bert_tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')","metadata":{"execution":{"iopub.status.busy":"2024-02-04T18:57:55.599858Z","iopub.execute_input":"2024-02-04T18:57:55.600270Z","iopub.status.idle":"2024-02-04T18:58:04.504786Z","shell.execute_reply.started":"2024-02-04T18:57:55.600238Z","shell.execute_reply":"2024-02-04T18:58:04.503579Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed219a23c4c54280a64329b0abf25f2c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8f13ac3d87a49fb88722bb1ab4c8745"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"547bc3f212df4f06bc6ec205e6a4f3c5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00a6752241054f33ad380a910f7d85e1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c7b1cc3ff78457c9e423f2fa13b80dc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a1dc45bef6f4ad2bd5e789f023540bd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36108ac56eab42f8a634d575d09d9849"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5024ac010b804e1cb9e1f21395377480"}},"metadata":{}}]},{"cell_type":"code","source":"# Saving the tokenizers\nbert_tokenizer.save_pretrained('bert-tokenizer')\ndistil_bert_tokenizer.save_pretrained('distil-bert')","metadata":{"execution":{"iopub.status.busy":"2024-02-04T19:11:13.103559Z","iopub.execute_input":"2024-02-04T19:11:13.104770Z","iopub.status.idle":"2024-02-04T19:11:13.202167Z","shell.execute_reply.started":"2024-02-04T19:11:13.104726Z","shell.execute_reply":"2024-02-04T19:11:13.201033Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"('distil-bert/tokenizer_config.json',\n 'distil-bert/special_tokens_map.json',\n 'distil-bert/vocab.txt',\n 'distil-bert/added_tokens.json',\n 'distil-bert/tokenizer.json')"},"metadata":{}}]},{"cell_type":"code","source":"!zip -r bert-tokenizer.zip /kaggle/working/bert-tokenizer","metadata":{"execution":{"iopub.status.busy":"2024-02-04T19:13:03.832731Z","iopub.execute_input":"2024-02-04T19:13:03.834276Z","iopub.status.idle":"2024-02-04T19:13:05.233080Z","shell.execute_reply.started":"2024-02-04T19:13:03.834228Z","shell.execute_reply":"2024-02-04T19:13:05.230209Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"  adding: kaggle/working/bert-tokenizer/ (stored 0%)\n  adding: kaggle/working/bert-tokenizer/special_tokens_map.json (deflated 52%)\n  adding: kaggle/working/bert-tokenizer/vocab.json (deflated 59%)\n  adding: kaggle/working/bert-tokenizer/tokenizer_config.json (deflated 76%)\n  adding: kaggle/working/bert-tokenizer/merges.txt (deflated 53%)\n  adding: kaggle/working/bert-tokenizer/tokenizer.json (deflated 72%)\n","output_type":"stream"}]},{"cell_type":"code","source":"!zip -r distill-bert-tokenizer.zip /kaggle/working/distil-bert","metadata":{"execution":{"iopub.status.busy":"2024-02-04T19:13:10.759532Z","iopub.execute_input":"2024-02-04T19:13:10.759989Z","iopub.status.idle":"2024-02-04T19:13:11.960436Z","shell.execute_reply.started":"2024-02-04T19:13:10.759930Z","shell.execute_reply":"2024-02-04T19:13:11.958837Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"  adding: kaggle/working/distil-bert/ (stored 0%)\n  adding: kaggle/working/distil-bert/special_tokens_map.json (deflated 42%)\n  adding: kaggle/working/distil-bert/vocab.txt (deflated 53%)\n  adding: kaggle/working/distil-bert/tokenizer_config.json (deflated 76%)\n  adding: kaggle/working/distil-bert/tokenizer.json (deflated 71%)\n","output_type":"stream"}]}]}