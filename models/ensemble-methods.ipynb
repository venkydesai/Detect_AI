{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Methods\n",
    "\n",
    "In this notebook, I want to try out some ensemble methods to see how they \"upgrade\" performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from catboost import CatBoostClassifier\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the data\n",
    "training = pd.read_csv('../../data/train-noisy-grammar.csv')\n",
    "valid = pd.read_csv('../../data/validation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating data into X and y\n",
    "X_train = training.drop(['row_id','essay','LLM_written','prompt'],axis=1)\n",
    "X_valid = valid.drop(['row_id','essay','LLM_written','prompt'],axis=1)\n",
    "y_train = training['LLM_written'].values\n",
    "y_valid = valid['LLM_written'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the scalar and scaling\n",
    "with open('../../models/custom-features/noisy-grammar-errors/scalar-noisy.pkl','rb') as file:\n",
    "    scalar = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical = ['word_count','stop_word_count','stop_word_ratio','unique_word_count','unique_word_ratio',\n",
    "             'count_question','count_exclamation','count_semi','count_colon','grammar_errors']\n",
    "X_train[numerical] = scalar.transform(X_train[numerical])\n",
    "X_valid[numerical] = scalar.transform(X_valid[numerical])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the RF model\n",
    "with open('../../models/custom-features/noisy-grammar-errors/fine-tuned/forest-fine-noisy.pkl','rb') as model:\n",
    "    forest = pickle.load(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x1292a06d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting GB model\n",
    "catboost_clf = CatBoostClassifier()\n",
    "catboost_clf.load_model('../../models/custom-features/noisy-grammar-errors/fine-tuned/catboost-noisy-fine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ANN(\n",
       "  (model): Sequential(\n",
       "    (0): Linear(in_features=515, out_features=10, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=10, out_features=20, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.2, inplace=False)\n",
       "    (6): Linear(in_features=20, out_features=10, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Dropout(p=0.2, inplace=False)\n",
       "    (9): Linear(in_features=10, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the ANN\n",
    "# Class for the model\n",
    "class ANN(nn.Module):\n",
    "    # Constructor\n",
    "    def __init__(self,num_features,model_layers,include_dropout,dropout_rate):\n",
    "        # Calling super constructor\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential()\n",
    "\n",
    "        # Adding the layers\n",
    "        in_features = num_features\n",
    "        for index in range(len(model_layers)):\n",
    "            model_layer = nn.Linear(in_features,model_layers[index],bias=True)\n",
    "            self.model.append(model_layer)\n",
    "            self.model.append(nn.ReLU())\n",
    "            in_features = model_layers[index]\n",
    "\n",
    "            # Adding dropout if specified\n",
    "            if include_dropout[index]:\n",
    "                self.model.append(nn.Dropout(p=dropout_rate))\n",
    "        \n",
    "        # Adding the final layer\n",
    "        self.model.append(nn.Linear(in_features,1))\n",
    "\n",
    "    # Forward class\n",
    "    def forward(self,X):\n",
    "        # Running the input through the model \n",
    "        return nn.functional.sigmoid(self.model(X))\n",
    "    \n",
    "num_features = X_train.shape[1]\n",
    "layers = [10,20,10]\n",
    "include_dropout = [True] * 3\n",
    "dropout_rate = 0.2\n",
    "\n",
    "ann = ANN(num_features,layers,include_dropout,dropout_rate)\n",
    "ann.load_state_dict(torch.load('../../models/custom-features/noisy-grammar-errors/ann.pt'))\n",
    "ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting both into Tensors and into a dataloader for iterating\n",
    "X_train_tensor = torch.from_numpy(X_train.values)\n",
    "y_train_tensor = torch.from_numpy(y_train)\n",
    "X_valid_tensor = torch.from_numpy(X_valid.values)\n",
    "y_valid_tensor = torch.from_numpy(y_valid)\n",
    "training_dataset = TensorDataset(X_train_tensor,y_train_tensor)\n",
    "valid_dataset = TensorDataset(X_valid_tensor,y_valid_tensor)\n",
    "training_loader = DataLoader(training_dataset,batch_size=32,shuffle=False)\n",
    "valid_loader = DataLoader(valid_dataset,batch_size=32,shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making the Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF predictions\n",
    "predictions_rf_train = forest.predict_proba(X_train.values)[:,1]\n",
    "predictions_rf_valid = forest.predict_proba(X_valid.values)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting Predictions\n",
    "predictions_gb_train = catboost_clf.predict_proba(X_train)[:,1]\n",
    "predictions_gb_valid = catboost_clf.predict_proba(X_valid)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making Predictions with ANN\n",
    "with torch.no_grad():\n",
    "    ann.eval()\n",
    "    train_preds_ann = None\n",
    "    val_preds_ann = None\n",
    "    for X,_ in training_loader:\n",
    "        # Making predictions\n",
    "        X = X.to(torch.float32)\n",
    "        pred = ann(X)\n",
    "        if train_preds_ann is None:\n",
    "            train_preds_ann = pred.detach().numpy()\n",
    "        else:\n",
    "            train_preds_ann = np.append(train_preds_ann,pred.detach().numpy(),axis=0)\n",
    "\n",
    "    for X,_ in valid_loader:\n",
    "        # Making predictions\n",
    "        X = X.to(torch.float32)\n",
    "        pred = ann(X)\n",
    "        if val_preds_ann is None:\n",
    "            val_preds_ann = pred.detach().numpy()\n",
    "        else:\n",
    "            val_preds_ann = np.append(val_preds_ann,pred.detach().numpy(),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Squeezing the last dimension out for the ann ones\n",
    "train_preds_ann = train_preds_ann.squeeze(-1)\n",
    "val_preds_ann = val_preds_ann.squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dictionary for the model performances\n",
    "performances = {\n",
    "    'model':[],\n",
    "    'Train ROC AUC':[],\n",
    "    'Valid ROC AUC':[]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trial 1: Random Forest + Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the training predictions\n",
    "final_predictions_train = (predictions_rf_train + predictions_gb_train) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the validation predictions\n",
    "final_predictions_valid = (predictions_rf_valid + predictions_gb_valid) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for Random Forest + Gradient Boosting\n",
      "Training ROC AUC: 0.9998957122972557\n",
      "Validation ROC AUC: 0.9766543982633817\n"
     ]
    }
   ],
   "source": [
    "# Making predictions\n",
    "print('Predictions for Random Forest + Gradient Boosting')\n",
    "train_score = roc_auc_score(y_train,final_predictions_train)\n",
    "valid_score = roc_auc_score(y_valid,final_predictions_valid)\n",
    "print(f'Training ROC AUC: {train_score}')\n",
    "print(f'Validation ROC AUC: {valid_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the metrics\n",
    "model = 'Random Forest + Gradient Boosting'\n",
    "performances['model'].append(model)\n",
    "performances['Train ROC AUC'].append(train_score)\n",
    "performances['Valid ROC AUC'].append(valid_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting + ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the training predictions\n",
    "final_predictions_train = (train_preds_ann + predictions_gb_train) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the validation predictions\n",
    "final_predictions_valid = (val_preds_ann + predictions_gb_valid) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for Gradient Boosting + ANN\n",
      "Training ROC AUC: 0.9999759895955058\n",
      "Validation ROC AUC: 0.977667316810433\n"
     ]
    }
   ],
   "source": [
    "# Making predictions\n",
    "print('Predictions for Gradient Boosting + ANN')\n",
    "train_score = roc_auc_score(y_train,final_predictions_train)\n",
    "valid_score = roc_auc_score(y_valid,final_predictions_valid)\n",
    "print(f'Training ROC AUC: {train_score}')\n",
    "print(f'Validation ROC AUC: {valid_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the metrics\n",
    "model = 'Gradient Boosting + ANN'\n",
    "performances['model'].append(model)\n",
    "performances['Train ROC AUC'].append(train_score)\n",
    "performances['Valid ROC AUC'].append(valid_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest + ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the training predictions\n",
    "final_predictions_train = (train_preds_ann + predictions_rf_train) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the validation predictions\n",
    "final_predictions_valid = (val_preds_ann + predictions_rf_valid) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for Random Forest + ANN\n",
      "Training ROC AUC: 0.9995142066887411\n",
      "Validation ROC AUC: 0.9809386552633081\n"
     ]
    }
   ],
   "source": [
    "# Making predictions\n",
    "print('Predictions for Random Forest + ANN')\n",
    "train_score = roc_auc_score(y_train,final_predictions_train)\n",
    "valid_score = roc_auc_score(y_valid,final_predictions_valid)\n",
    "print(f'Training ROC AUC: {train_score}')\n",
    "print(f'Validation ROC AUC: {valid_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the metrics\n",
    "model = 'Random Forest + ANN'\n",
    "performances['model'].append(model)\n",
    "performances['Train ROC AUC'].append(train_score)\n",
    "performances['Valid ROC AUC'].append(valid_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest + Gradient Boosting + ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the training predictions\n",
    "final_predictions_train = (train_preds_ann + predictions_rf_train + predictions_gb_train) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the validation predictions\n",
    "final_predictions_valid = (val_preds_ann + predictions_rf_valid + predictions_gb_valid) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for Random Forest + Gradient Boosting +  ANN\n",
      "Training ROC AUC: 0.9999479425402964\n",
      "Validation ROC AUC: 0.9797768837167549\n"
     ]
    }
   ],
   "source": [
    "# Making predictions\n",
    "print('Predictions for Random Forest + Gradient Boosting +  ANN')\n",
    "train_score = roc_auc_score(y_train,final_predictions_train)\n",
    "valid_score = roc_auc_score(y_valid,final_predictions_valid)\n",
    "print(f'Training ROC AUC: {train_score}')\n",
    "print(f'Validation ROC AUC: {valid_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the metrics\n",
    "model = 'Random Forest + Gradient Boostin + ANN'\n",
    "performances['model'].append(model)\n",
    "performances['Train ROC AUC'].append(train_score)\n",
    "performances['Valid ROC AUC'].append(valid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Train ROC AUC</th>\n",
       "      <th>Valid ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest + Gradient Boosting</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>0.976654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gradient Boosting + ANN</td>\n",
       "      <td>0.999976</td>\n",
       "      <td>0.977667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest + ANN</td>\n",
       "      <td>0.999514</td>\n",
       "      <td>0.980939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest + Gradient Boostin + ANN</td>\n",
       "      <td>0.999948</td>\n",
       "      <td>0.979777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    model  Train ROC AUC  Valid ROC AUC\n",
       "0       Random Forest + Gradient Boosting       0.999896       0.976654\n",
       "1                 Gradient Boosting + ANN       0.999976       0.977667\n",
       "2                     Random Forest + ANN       0.999514       0.980939\n",
       "3  Random Forest + Gradient Boostin + ANN       0.999948       0.979777"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing out the model performances in a dataframe and saving it\n",
    "metrics_df = pd.DataFrame().from_dict(performances)\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the performances\n",
    "metrics_df.to_csv('../../models/custom-features/noisy-grammar-errors/ensemble-metrics.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All ensemble models do comparably well. It would be worth testing each of them on the test set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "authentic-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
