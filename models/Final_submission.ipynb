{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc23f8af",
   "metadata": {
    "papermill": {
     "duration": 0.009368,
     "end_time": "2024-02-04T22:27:23.444415",
     "exception": false,
     "start_time": "2024-02-04T22:27:23.435047",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# LLM Competition Submission\n",
    "\n",
    "This notebook represents my submission to the [LLM - Detect AI Generated Text](https://www.kaggle.com/competitions/llm-detect-ai-generated-text/overview) competition on Kaggle. This notebook was made on Kaggle as the competition is a code competition. This is why there may be some inconsistencies with the other code files and notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09ef8e15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-04T22:27:23.464688Z",
     "iopub.status.busy": "2024-02-04T22:27:23.463894Z",
     "iopub.status.idle": "2024-02-04T22:27:51.067278Z",
     "shell.execute_reply": "2024-02-04T22:27:51.065942Z"
    },
    "papermill": {
     "duration": 27.61651,
     "end_time": "2024-02-04T22:27:51.069972",
     "exception": false,
     "start_time": "2024-02-04T22:27:23.453462",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q language-tool-python --no-index --find-links ../input/daigt-misc/\n",
    "!mkdir -p /root/.cache/language_tool_python/\n",
    "!cp -r /kaggle/input/daigt-misc/lang57/LanguageTool-5.7 /root/.cache/language_tool_python/LanguageTool-5.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "167c2d8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-04T22:27:51.091040Z",
     "iopub.status.busy": "2024-02-04T22:27:51.090450Z",
     "iopub.status.idle": "2024-02-04T22:28:01.350362Z",
     "shell.execute_reply": "2024-02-04T22:28:01.349517Z"
    },
    "papermill": {
     "duration": 10.27291,
     "end_time": "2024-02-04T22:28:01.352685",
     "exception": false,
     "start_time": "2024-02-04T22:27:51.079775",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from tqdm import tqdm\n",
    "from torchtext.data import get_tokenizer\n",
    "import language_tool_python # Need to add the daigt-misc dataset for offline use\n",
    "import re\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Getting tqdm for pandas \n",
    "tqdm.pandas()\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774a5b0d",
   "metadata": {
    "papermill": {
     "duration": 0.009385,
     "end_time": "2024-02-04T22:28:01.372339",
     "exception": false,
     "start_time": "2024-02-04T22:28:01.362954",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "487e7812",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-04T22:28:01.393175Z",
     "iopub.status.busy": "2024-02-04T22:28:01.392709Z",
     "iopub.status.idle": "2024-02-04T22:28:01.422300Z",
     "shell.execute_reply": "2024-02-04T22:28:01.421385Z"
    },
    "papermill": {
     "duration": 0.042239,
     "end_time": "2024-02-04T22:28:01.424194",
     "exception": false,
     "start_time": "2024-02-04T22:28:01.381955",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preprocessor\n",
    "class Preprocessing():\n",
    "    # Constructor\n",
    "    def __init__(self,data_df:pd.DataFrame):\n",
    "        self.data = data_df\n",
    "        self.stop_words = stopwords.words('english')\n",
    "        self.tokenizer = RegexpTokenizer(r'[a-zA-Z]+') # tokenizer for words only\n",
    "        self.overall_tokenizer = get_tokenizer('spacy',language='en_core_web_sm')\n",
    "        self.grammar_checker = language_tool_python.LanguageTool('en-US',config={'cacheSize': 5000,'maxCheckThreads':20})\n",
    "        self.detector_tokenizer = AutoTokenizer.from_pretrained(\"../input/roberta-base-openai-detector/roberta-base-openai-detector\")\n",
    "        self.detector = AutoModelForSequenceClassification.from_pretrained(\"../input/roberta-base-openai-detector/roberta-base-openai-detector\")\n",
    "        self.emotion_tokenizer = AutoTokenizer.from_pretrained(\"../input/emotion-detector/emotion-english-distilroberta-base\")\n",
    "        self.emotion_detector = AutoModelForSequenceClassification.from_pretrained(\"../input/emotion-detector/emotion-english-distilroberta-base\")\n",
    "        self.emotions = ['anger','disgust','fear','joy','neutral','sadness','surprise']\n",
    "\n",
    "        print('Tokenizing the essays into only words...')\n",
    "        self.data['tokenized_essay_words'] = self.data['essay'].progress_apply(self.tokenize_essay_words)\n",
    "        print()\n",
    "        print('Tokenizing the essays into overall tokens with words and punctuation')\n",
    "        self.data['tokenized_overall'] = self.data['essay'].progress_apply(self.tokenize_overall)\n",
    "        print()\n",
    "    \n",
    "    # Function to tokenize each essay into words only\n",
    "    def tokenize_essay_words(self,essay:str) -> list:\n",
    "        return self.tokenizer.tokenize(essay)\n",
    "    \n",
    "    # Function to tokenize each essay into overall tokens\n",
    "    def tokenize_overall(self,essay:str) -> list:\n",
    "        return self.overall_tokenizer(essay)\n",
    "    \n",
    "    # Getting the count of stop words in an essay\n",
    "    def get_stop_word_count(self,text:str) -> int:\n",
    "        count = 0\n",
    "        for word in text:\n",
    "            if word in self.stop_words:\n",
    "                count += 1\n",
    "        return count\n",
    "    \n",
    "    # Getting the count of the unique words in an essay\n",
    "    def get_unique_words(self,essay:list) -> int:\n",
    "        return len(set(essay))\n",
    "    \n",
    "    # Getting the counts of each punctuation (?, !, ;, :)\n",
    "    def count_punc(self, essay:list) -> tuple[int,int,int,int]:\n",
    "        count_q = 0\n",
    "        count_ex = 0\n",
    "        count_semi = 0\n",
    "        count_col = 0\n",
    "\n",
    "        # Iterating through the tokenized essay\n",
    "        for token in essay:\n",
    "            if token == \"?\":\n",
    "                count_q += 1\n",
    "            elif token == \"!\":\n",
    "                count_ex += 1\n",
    "            elif token == \";\":\n",
    "                count_semi += 1\n",
    "            elif token == \":\":\n",
    "                count_col += 1\n",
    "        \n",
    "        return count_q, count_ex,count_semi, count_col\n",
    "    \n",
    "    # A function to get the number of grammatical errors\n",
    "    def get_grammar_error_count(self,essay:str) -> int:\n",
    "        errors = self.grammar_checker.check(essay)\n",
    "        return len(errors)\n",
    "    \n",
    "    # A function to get the detection from OpenAI's GPT-2 Detector\n",
    "    def get_detect_pred(self,text:str) -> int:\n",
    "        # Tokenizing the input essay\n",
    "        inputs = self.detector_tokenizer(text,return_tensors='pt',truncation=True).to(device)\n",
    "\n",
    "        # Getting the logits\n",
    "        with torch.no_grad():\n",
    "            logits = self.detector(**inputs).logits\n",
    "\n",
    "        # Doing 1 - max logit because the model has \"Real\" = class 1 and \"Fake\" = class 0\n",
    "        # My labels are the opposite, 1 = LLM Written and 0 = student written.\n",
    "        # If a logit = 0 = Fake, 1-0 = 1 = LLM Written\n",
    "        # If a logit = 1 = Real, 1-1 = 0 = student written\n",
    "        predicted_class = 1 - logits.argmax().item()\n",
    "        return predicted_class\n",
    "    \n",
    "    # A function to get the prediction from the Emotion Detector\n",
    "    def emotion_detector_pred(self,essay:str) -> tuple[int,int,int,int]:\n",
    "        # Tokenizing the input essay\n",
    "        inputs = self.emotion_tokenizer(essay,return_tensors='pt',truncation=True).to(device)\n",
    "\n",
    "        # Getting the logits\n",
    "        with torch.no_grad():\n",
    "            logits = self.emotion_detector(**inputs).logits\n",
    "\n",
    "        # Getting the predicted emotion\n",
    "        predicted_emotion = self.emotions[logits.argmax().item()]\n",
    "        if predicted_emotion == 'anger':\n",
    "            return 1,0,0,0\n",
    "        elif predicted_emotion == 'surprise':\n",
    "            return 0,1,0,0\n",
    "        elif predicted_emotion == 'sadness':\n",
    "            return 0,0,1,0\n",
    "        elif predicted_emotion == 'fear':\n",
    "            return 0,0,0,1\n",
    "        else:\n",
    "            return 0,0,0,0\n",
    "    \n",
    "    # A function to knit all preprocessing together\n",
    "    def preprocessing(self) -> pd.DataFrame:\n",
    "        # Getting the stop word count and the stop word ratio\n",
    "        print('Adding the stop word features...')\n",
    "        self.data['stop_word_count'] = self.data['tokenized_essay_words'].progress_apply(self.get_stop_word_count)\n",
    "        self.data['stop_word_ratio'] = self.data['stop_word_count'] / self.data['word_count']\n",
    "        print()\n",
    "        \n",
    "        # Getting the unique word counts and the unique word ratio\n",
    "        print('Adding the unique word features...')\n",
    "        self.data['unique_word_count'] = self.data['tokenized_essay_words'].progress_apply(self.get_unique_words)\n",
    "        self.data['unique_word_ratio'] = self.data['unique_word_count'] / self.data['word_count']\n",
    "        print()\n",
    "\n",
    "        # Adding the punctuation features\n",
    "        print('Adding the punctuation features...')\n",
    "        punc_counts = self.data['tokenized_overall'].progress_apply(self.count_punc)\n",
    "        self.data['count_question'] = [row[0] for row in punc_counts]\n",
    "        self.data['count_exclamation'] = [row[1] for row in punc_counts]\n",
    "        self.data['count_semi'] = [row[2] for row in punc_counts]\n",
    "        self.data['count_colon'] = [row[3] for row in punc_counts]\n",
    "        print()\n",
    "\n",
    "        # Getting the number of grammatical errors\n",
    "        print('Getting grammar error counts...')\n",
    "        self.data['grammar_errors'] = self.data['essay'].progress_apply(self.get_grammar_error_count)\n",
    "        print()\n",
    "\n",
    "        # Adding the detector model prediction\n",
    "        print('Getting Detector Prediction...')\n",
    "        self.data['detector_pred'] = self.data['essay'].progress_apply(self.get_detect_pred)\n",
    "        print()\n",
    "\n",
    "        # Getting the emotion model prediction\n",
    "        print('Getting Emotion Prediction...')\n",
    "        emotion_rows = self.data['essay'].progress_apply(self.emotion_detector_pred)\n",
    "        self.data['anger_pred'] = [row[0] for row in emotion_rows]\n",
    "        self.data['surprise_pred'] = [row[1] for row in emotion_rows]\n",
    "        self.data['sadness_pred'] = [row[2] for row in emotion_rows]\n",
    "        self.data['fear_pred'] = [row[3] for row in emotion_rows]\n",
    "        print()\n",
    "\n",
    "        # Dropping the tokenized parts\n",
    "        self.data.drop(['tokenized_essay_words','tokenized_overall'],axis=1,inplace=True)\n",
    "\n",
    "        # returning the preprocessed dataframe\n",
    "        return self.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68d6d770",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-04T22:28:01.444491Z",
     "iopub.status.busy": "2024-02-04T22:28:01.444171Z",
     "iopub.status.idle": "2024-02-04T22:28:01.460913Z",
     "shell.execute_reply": "2024-02-04T22:28:01.460128Z"
    },
    "papermill": {
     "duration": 0.02917,
     "end_time": "2024-02-04T22:28:01.463001",
     "exception": false,
     "start_time": "2024-02-04T22:28:01.433831",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Getting the test data\n",
    "test_data = pd.read_csv('../input/llm-detect-ai-generated-text/test_essays.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60c0915a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-04T22:28:01.485880Z",
     "iopub.status.busy": "2024-02-04T22:28:01.485556Z",
     "iopub.status.idle": "2024-02-04T22:28:01.496807Z",
     "shell.execute_reply": "2024-02-04T22:28:01.496033Z"
    },
    "papermill": {
     "duration": 0.024846,
     "end_time": "2024-02-04T22:28:01.498860",
     "exception": false,
     "start_time": "2024-02-04T22:28:01.474014",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# renaming columns\n",
    "test_data.rename(columns={'text':'essay'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07c7b1fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-04T22:28:01.520527Z",
     "iopub.status.busy": "2024-02-04T22:28:01.520205Z",
     "iopub.status.idle": "2024-02-04T22:28:01.531047Z",
     "shell.execute_reply": "2024-02-04T22:28:01.530041Z"
    },
    "papermill": {
     "duration": 0.024358,
     "end_time": "2024-02-04T22:28:01.533509",
     "exception": false,
     "start_time": "2024-02-04T22:28:01.509151",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 4620.97it/s]\n"
     ]
    }
   ],
   "source": [
    "# Adding a column for word count\n",
    "def get_word_count(text:str) -> int:\n",
    "    \"\"\"\n",
    "    get_word_count\n",
    "\n",
    "    A function to get the word count of some text.\n",
    "\n",
    "    inputs:\n",
    "    - text: a string that indicates you want to get the word count for.\n",
    "\n",
    "    outputs:\n",
    "    - an integer representing the word count\n",
    "    \"\"\"\n",
    "    return len(re.findall(r'[a-zA-Z_]+',text))\n",
    "\n",
    "test_data['word_count'] = test_data['essay'].progress_apply(get_word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf3b8131",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-04T22:28:01.555499Z",
     "iopub.status.busy": "2024-02-04T22:28:01.555213Z",
     "iopub.status.idle": "2024-02-04T22:28:21.448069Z",
     "shell.execute_reply": "2024-02-04T22:28:21.446798Z"
    },
    "papermill": {
     "duration": 19.906513,
     "end_time": "2024-02-04T22:28:21.450436",
     "exception": false,
     "start_time": "2024-02-04T22:28:01.543923",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing the essays into only words...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 3887.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tokenizing the essays into overall tokens with words and punctuation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 2139.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding the stop word features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 7512.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Adding the unique word features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 10347.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Adding the punctuation features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 9098.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Getting grammar error counts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:05<00:00,  1.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Getting Detector Prediction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Getting Emotion Prediction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 128.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating the preprocessing class\n",
    "preprocessor = Preprocessing(test_data)\n",
    "\n",
    "# Putting the model on GPU\n",
    "preprocessor.detector.to(device)\n",
    "preprocessor.emotion_detector.to(device)\n",
    "\n",
    "# Running data through preprocessing \n",
    "test_data_prepared = preprocessor.preprocessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8914dc3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-04T22:28:21.478195Z",
     "iopub.status.busy": "2024-02-04T22:28:21.477161Z",
     "iopub.status.idle": "2024-02-04T22:28:21.486166Z",
     "shell.execute_reply": "2024-02-04T22:28:21.485345Z"
    },
    "papermill": {
     "duration": 0.025415,
     "end_time": "2024-02-04T22:28:21.488763",
     "exception": false,
     "start_time": "2024-02-04T22:28:21.463348",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 7733.81it/s]\n"
     ]
    }
   ],
   "source": [
    "# Text cleaning \n",
    "def text_cleaning(essay:str) -> str:\n",
    "    cleaned_text = essay.replace('\\n',\"\")\n",
    "    cleaned_text = essay.replace(\"\\t\",\"\")\n",
    "    \n",
    "    return cleaned_text\n",
    "\n",
    "# Getting the training data and cleaning it\n",
    "essays_cleaned = test_data_prepared['essay'].progress_apply(text_cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d56b404f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-04T22:28:21.516072Z",
     "iopub.status.busy": "2024-02-04T22:28:21.515790Z",
     "iopub.status.idle": "2024-02-04T22:28:43.778664Z",
     "shell.execute_reply": "2024-02-04T22:28:43.777881Z"
    },
    "papermill": {
     "duration": 22.279183,
     "end_time": "2024-02-04T22:28:43.781301",
     "exception": false,
     "start_time": "2024-02-04T22:28:21.502118",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Getting the tfidf vectorizer and running the test data through it. \n",
    "with open('../input/llm-competition-models/tfidf-vectorizer-kaggle.pk/tfidf-vectorizer-kaggle.pk','rb') as file:\n",
    "    vectorizer = pickle.load(file)\n",
    "\n",
    "vectorized = vectorizer.transform(essays_cleaned)\n",
    "transformed_data = pd.DataFrame(vectorized.toarray(),columns=vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f43b4c8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-04T22:28:43.809077Z",
     "iopub.status.busy": "2024-02-04T22:28:43.808765Z",
     "iopub.status.idle": "2024-02-04T22:28:43.814862Z",
     "shell.execute_reply": "2024-02-04T22:28:43.814119Z"
    },
    "papermill": {
     "duration": 0.021511,
     "end_time": "2024-02-04T22:28:43.816774",
     "exception": false,
     "start_time": "2024-02-04T22:28:43.795263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Combining the dataframes\n",
    "combined_data = pd.concat([test_data_prepared,transformed_data],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91caf759",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-04T22:28:43.843548Z",
     "iopub.status.busy": "2024-02-04T22:28:43.843252Z",
     "iopub.status.idle": "2024-02-04T22:28:43.848795Z",
     "shell.execute_reply": "2024-02-04T22:28:43.847808Z"
    },
    "papermill": {
     "duration": 0.021162,
     "end_time": "2024-02-04T22:28:43.850965",
     "exception": false,
     "start_time": "2024-02-04T22:28:43.829803",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dropping the other columns\n",
    "combined_data.drop(['id','prompt_id','essay'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3085add8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-04T22:28:43.879873Z",
     "iopub.status.busy": "2024-02-04T22:28:43.879558Z",
     "iopub.status.idle": "2024-02-04T22:28:43.891505Z",
     "shell.execute_reply": "2024-02-04T22:28:43.890796Z"
    },
    "papermill": {
     "duration": 0.02836,
     "end_time": "2024-02-04T22:28:43.893503",
     "exception": false,
     "start_time": "2024-02-04T22:28:43.865143",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Getting the scalar and scaling\n",
    "with open('../input/llm-competition-models/scalar-noisy.pkl','rb') as file:\n",
    "    scalar = pickle.load(file)\n",
    "\n",
    "numerical = ['word_count','stop_word_count','stop_word_ratio','unique_word_count','unique_word_ratio',\n",
    "             'count_question','count_exclamation','count_semi','count_colon','grammar_errors']\n",
    "combined_data[numerical] = scalar.transform(combined_data[numerical])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1e02fb1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-04T22:28:43.919755Z",
     "iopub.status.busy": "2024-02-04T22:28:43.919471Z",
     "iopub.status.idle": "2024-02-04T22:28:46.433056Z",
     "shell.execute_reply": "2024-02-04T22:28:46.432116Z"
    },
    "papermill": {
     "duration": 2.528951,
     "end_time": "2024-02-04T22:28:46.435242",
     "exception": false,
     "start_time": "2024-02-04T22:28:43.906291",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7f595cab63b0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the model\n",
    "catboost_model = CatBoostClassifier()\n",
    "catboost_model.load_model('../input/llm-competition-models/catboost-noisy-fine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c0f5867",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-04T22:28:46.462728Z",
     "iopub.status.busy": "2024-02-04T22:28:46.462368Z",
     "iopub.status.idle": "2024-02-04T22:28:49.073078Z",
     "shell.execute_reply": "2024-02-04T22:28:49.071979Z"
    },
    "papermill": {
     "duration": 2.627625,
     "end_time": "2024-02-04T22:28:49.075922",
     "exception": false,
     "start_time": "2024-02-04T22:28:46.448297",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions_catboost = catboost_model.predict_proba(combined_data)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02c08b9",
   "metadata": {
    "papermill": {
     "duration": 0.011925,
     "end_time": "2024-02-04T22:28:49.102309",
     "exception": false,
     "start_time": "2024-02-04T22:28:49.090384",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## DistilBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3704cf99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-04T22:28:49.127762Z",
     "iopub.status.busy": "2024-02-04T22:28:49.127430Z",
     "iopub.status.idle": "2024-02-04T22:28:49.132612Z",
     "shell.execute_reply": "2024-02-04T22:28:49.131780Z"
    },
    "papermill": {
     "duration": 0.019965,
     "end_time": "2024-02-04T22:28:49.134442",
     "exception": false,
     "start_time": "2024-02-04T22:28:49.114477",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "def preprocess(essay:str):\n",
    "    preprocessed_essay = essay.lower()\n",
    "    \n",
    "    # Subbing out \\n and \\t\n",
    "    preprocessed_essay = re.sub(\"\\n\",\"\",preprocessed_essay)\n",
    "    preprocessed_essay = re.sub(\"\\t\",\"\",preprocessed_essay)\n",
    "\n",
    "    # Replacing /xa0 = non-breaking space in Latin1\n",
    "    preprocessed_essay = preprocessed_essay.replace(u'\\xa0', u' ')\n",
    "    \n",
    "    return preprocessed_essay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54f7efeb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-04T22:28:49.160928Z",
     "iopub.status.busy": "2024-02-04T22:28:49.160646Z",
     "iopub.status.idle": "2024-02-04T22:28:49.168122Z",
     "shell.execute_reply": "2024-02-04T22:28:49.167127Z"
    },
    "papermill": {
     "duration": 0.022966,
     "end_time": "2024-02-04T22:28:49.170315",
     "exception": false,
     "start_time": "2024-02-04T22:28:49.147349",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 4888.47it/s]\n"
     ]
    }
   ],
   "source": [
    "# Running the training essays and validation essays through preprocessing\n",
    "preprocessed_essays = test_data['essay'].progress_apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1856d82d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-04T22:28:49.242311Z",
     "iopub.status.busy": "2024-02-04T22:28:49.241968Z",
     "iopub.status.idle": "2024-02-04T22:28:51.131938Z",
     "shell.execute_reply": "2024-02-04T22:28:51.130964Z"
    },
    "papermill": {
     "duration": 1.906822,
     "end_time": "2024-02-04T22:28:51.134134",
     "exception": false,
     "start_time": "2024-02-04T22:28:49.227312",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the tokenizer and model, using DistilBERT\n",
    "tokenizer = AutoTokenizer.from_pretrained('../input/llm-competition-models/distil-bert-tokenizer/distil-bert-tokenizer')\n",
    "distil_model = AutoModelForSequenceClassification.from_pretrained('../input/llm-competition-models/fine-tuned-distillBert/fine-tuned-distillBert')\n",
    "distil_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2001d81e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-04T22:28:51.162914Z",
     "iopub.status.busy": "2024-02-04T22:28:51.162612Z",
     "iopub.status.idle": "2024-02-04T22:28:51.168353Z",
     "shell.execute_reply": "2024-02-04T22:28:51.167421Z"
    },
    "papermill": {
     "duration": 0.022512,
     "end_time": "2024-02-04T22:28:51.170436",
     "exception": false,
     "start_time": "2024-02-04T22:28:51.147924",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Defining a function for inference\n",
    "def inference(essay:str) -> float:\n",
    "    # Tokenizing the input essay\n",
    "    inputs = tokenizer(essay,padding='max_length',truncation=True,max_length=512,return_tensors='pt').to(device)\n",
    "    \n",
    "    # Getting the logits\n",
    "    with torch.no_grad():\n",
    "        logits = distil_model(**inputs).logits\n",
    "        probability = nn.functional.sigmoid(logits)\n",
    "    return probability.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "270b8a8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-04T22:28:51.198666Z",
     "iopub.status.busy": "2024-02-04T22:28:51.197855Z",
     "iopub.status.idle": "2024-02-04T22:28:51.303392Z",
     "shell.execute_reply": "2024-02-04T22:28:51.302358Z"
    },
    "papermill": {
     "duration": 0.122136,
     "end_time": "2024-02-04T22:28:51.305597",
     "exception": false,
     "start_time": "2024-02-04T22:28:51.183461",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 30.60it/s]\n"
     ]
    }
   ],
   "source": [
    "# Running the examples through the model\n",
    "distil_pred = preprocessed_essays.progress_apply(inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2f4a7a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-04T22:28:51.335549Z",
     "iopub.status.busy": "2024-02-04T22:28:51.335219Z",
     "iopub.status.idle": "2024-02-04T22:28:51.343200Z",
     "shell.execute_reply": "2024-02-04T22:28:51.342125Z"
    },
    "papermill": {
     "duration": 0.025674,
     "end_time": "2024-02-04T22:28:51.345697",
     "exception": false,
     "start_time": "2024-02-04T22:28:51.320023",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Combining predictions with ids\n",
    "submission = pd.DataFrame()\n",
    "submission['id'] = test_data['id']\n",
    "submission['generated'] = (predictions_catboost + distil_pred) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "51c4eb3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-04T22:28:51.376032Z",
     "iopub.status.busy": "2024-02-04T22:28:51.375743Z",
     "iopub.status.idle": "2024-02-04T22:28:51.382967Z",
     "shell.execute_reply": "2024-02-04T22:28:51.382122Z"
    },
    "papermill": {
     "duration": 0.024337,
     "end_time": "2024-02-04T22:28:51.385274",
     "exception": false,
     "start_time": "2024-02-04T22:28:51.360937",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4a1285",
   "metadata": {
    "papermill": {
     "duration": 0.013686,
     "end_time": "2024-02-04T22:28:51.414980",
     "exception": false,
     "start_time": "2024-02-04T22:28:51.401294",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Checking Training & Validation Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f8be0731",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-04T22:28:51.443530Z",
     "iopub.status.busy": "2024-02-04T22:28:51.443233Z",
     "iopub.status.idle": "2024-02-04T22:28:51.447098Z",
     "shell.execute_reply": "2024-02-04T22:28:51.446351Z"
    },
    "papermill": {
     "duration": 0.020284,
     "end_time": "2024-02-04T22:28:51.449118",
     "exception": false,
     "start_time": "2024-02-04T22:28:51.428834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# # Getting the data\n",
    "# training_data = pd.read_csv('../input/training-llm-competition/train.csv')\n",
    "# valid_data = pd.read_csv('../input/training-llm-competition/validation.csv')\n",
    "\n",
    "# # Making copies\n",
    "# train_data_copy = training_data.copy()\n",
    "# valid_data_copy = valid_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce5d8c43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-04T22:28:51.478632Z",
     "iopub.status.busy": "2024-02-04T22:28:51.478295Z",
     "iopub.status.idle": "2024-02-04T22:28:51.482264Z",
     "shell.execute_reply": "2024-02-04T22:28:51.481428Z"
    },
    "papermill": {
     "duration": 0.0208,
     "end_time": "2024-02-04T22:28:51.484184",
     "exception": false,
     "start_time": "2024-02-04T22:28:51.463384",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Text cleaning \n",
    "# def text_cleaning(essay:str) -> str:\n",
    "#     cleaned_text = essay.replace('\\n',\"\")\n",
    "#     cleaned_text = essay.replace(\"\\t\",\"\")\n",
    "    \n",
    "#     return cleaned_text\n",
    "\n",
    "# train_data_copy['essay'] = train_data_copy['essay'].progress_apply(text_cleaning)\n",
    "# valid_data_copy['essay'] = valid_data_copy['essay'].progress_apply(text_cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "38bc6bda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-04T22:28:51.513557Z",
     "iopub.status.busy": "2024-02-04T22:28:51.512713Z",
     "iopub.status.idle": "2024-02-04T22:28:51.517288Z",
     "shell.execute_reply": "2024-02-04T22:28:51.516566Z"
    },
    "papermill": {
     "duration": 0.020896,
     "end_time": "2024-02-04T22:28:51.519184",
     "exception": false,
     "start_time": "2024-02-04T22:28:51.498288",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Getting the scalar and scaling\n",
    "# with open('../input/llm-competition-models/scalar-noisy.pkl','rb') as file:\n",
    "#     scalar = pickle.load(file)\n",
    "\n",
    "# numerical = ['word_count','stop_word_count','stop_word_ratio','unique_word_count','unique_word_ratio',\n",
    "#              'count_question','count_exclamation','count_semi','count_colon','grammar_errors']\n",
    "# train_data_copy[numerical] = scalar.transform(train_data_copy[numerical])\n",
    "# valid_data_copy[numerical] = scalar.transform(valid_data_copy[numerical])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "58bc70b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-04T22:28:51.548625Z",
     "iopub.status.busy": "2024-02-04T22:28:51.548326Z",
     "iopub.status.idle": "2024-02-04T22:28:51.552289Z",
     "shell.execute_reply": "2024-02-04T22:28:51.551457Z"
    },
    "papermill": {
     "duration": 0.020993,
     "end_time": "2024-02-04T22:28:51.554209",
     "exception": false,
     "start_time": "2024-02-04T22:28:51.533216",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Getting the model\n",
    "# catboost_model = CatBoostClassifier()\n",
    "# catboost_model.load_model('../input/llm-competition-models/catboost-noisy-fine')\n",
    "\n",
    "# # Making predictions on training and validation\n",
    "# predictions_catboost_train = catboost_model.predict_proba(train_data_copy.drop(['row_id','essay','LLM_written','prompt'],axis=1))[:,1]\n",
    "# predictions_catboost_valid = catboost_model.predict_proba(valid_data_copy.drop(['row_id','essay','LLM_written','prompt'],axis=1))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "13435f61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-04T22:28:51.582637Z",
     "iopub.status.busy": "2024-02-04T22:28:51.582321Z",
     "iopub.status.idle": "2024-02-04T22:28:51.586456Z",
     "shell.execute_reply": "2024-02-04T22:28:51.585636Z"
    },
    "papermill": {
     "duration": 0.020473,
     "end_time": "2024-02-04T22:28:51.588437",
     "exception": false,
     "start_time": "2024-02-04T22:28:51.567964",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Preprocessing\n",
    "# def preprocess(essay:str):\n",
    "#     preprocessed_essay = essay.lower()\n",
    "    \n",
    "#     # Subbing out \\n and \\t\n",
    "#     preprocessed_essay = re.sub(\"\\n\",\"\",preprocessed_essay)\n",
    "#     preprocessed_essay = re.sub(\"\\t\",\"\",preprocessed_essay)\n",
    "\n",
    "#     # Replacing /xa0 = non-breaking space in Latin1\n",
    "#     preprocessed_essay = preprocessed_essay.replace(u'\\xa0', u' ')\n",
    "    \n",
    "#     return preprocessed_essay\n",
    "# train_data_copy['essay'] = training_data['essay'].progress_apply(preprocess)\n",
    "# valid_data_copy['essay'] = valid_data['essay'].progress_apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "85841482",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-04T22:28:51.617560Z",
     "iopub.status.busy": "2024-02-04T22:28:51.617303Z",
     "iopub.status.idle": "2024-02-04T22:28:51.621020Z",
     "shell.execute_reply": "2024-02-04T22:28:51.620162Z"
    },
    "papermill": {
     "duration": 0.020609,
     "end_time": "2024-02-04T22:28:51.622884",
     "exception": false,
     "start_time": "2024-02-04T22:28:51.602275",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Getting the tokenizer and model, using DistilBERT\n",
    "# tokenizer = AutoTokenizer.from_pretrained('../input/llm-competition-models/distil-bert-tokenizer/distil-bert-tokenizer')\n",
    "# distil_model = AutoModelForSequenceClassification.from_pretrained('../input/llm-competition-models/fine-tuned-distillBert/fine-tuned-distillBert')\n",
    "# distil_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3bf2e05d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-04T22:28:51.651292Z",
     "iopub.status.busy": "2024-02-04T22:28:51.651039Z",
     "iopub.status.idle": "2024-02-04T22:28:51.654987Z",
     "shell.execute_reply": "2024-02-04T22:28:51.654168Z"
    },
    "papermill": {
     "duration": 0.020252,
     "end_time": "2024-02-04T22:28:51.656951",
     "exception": false,
     "start_time": "2024-02-04T22:28:51.636699",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Defining a function for inference\n",
    "# def inference(essay:str) -> float:\n",
    "#     # Tokenizing the input essay\n",
    "#     inputs = tokenizer(essay,padding='max_length',truncation=True,max_length=512,return_tensors='pt').to(device)\n",
    "    \n",
    "#     # Getting the logits\n",
    "#     with torch.no_grad():\n",
    "#         logits = distil_model(**inputs).logits\n",
    "#         probability = nn.functional.sigmoid(logits)\n",
    "#     return probability.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ecb6347e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-04T22:28:51.685613Z",
     "iopub.status.busy": "2024-02-04T22:28:51.685312Z",
     "iopub.status.idle": "2024-02-04T22:28:51.688846Z",
     "shell.execute_reply": "2024-02-04T22:28:51.688009Z"
    },
    "papermill": {
     "duration": 0.019882,
     "end_time": "2024-02-04T22:28:51.690766",
     "exception": false,
     "start_time": "2024-02-04T22:28:51.670884",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# distil_pred_train = train_data_copy['essay'].progress_apply(inference)\n",
    "# distil_pred_valid = valid_data_copy['essay'].progress_apply(inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "df06d997",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-04T22:28:51.719448Z",
     "iopub.status.busy": "2024-02-04T22:28:51.719132Z",
     "iopub.status.idle": "2024-02-04T22:28:51.723312Z",
     "shell.execute_reply": "2024-02-04T22:28:51.722384Z"
    },
    "papermill": {
     "duration": 0.021083,
     "end_time": "2024-02-04T22:28:51.725436",
     "exception": false,
     "start_time": "2024-02-04T22:28:51.704353",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Getting the final predictions\n",
    "# final_pred_train = (distil_pred_train + predictions_catboost_train) / 2\n",
    "# final_pred_valid = (distil_pred_valid + predictions_catboost_valid) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "26f6818a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-04T22:28:51.756476Z",
     "iopub.status.busy": "2024-02-04T22:28:51.756171Z",
     "iopub.status.idle": "2024-02-04T22:28:51.760251Z",
     "shell.execute_reply": "2024-02-04T22:28:51.759326Z"
    },
    "papermill": {
     "duration": 0.021989,
     "end_time": "2024-02-04T22:28:51.762408",
     "exception": false,
     "start_time": "2024-02-04T22:28:51.740419",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Making predictions\n",
    "# print('Predictions for Ensemble')\n",
    "# train_score = roc_auc_score(training_data['LLM_written'],final_pred_train)\n",
    "# valid_score = roc_auc_score(valid_data['LLM_written'],final_pred_valid)\n",
    "# print(f'Training ROC AUC: {train_score}')\n",
    "# print(f'Validation ROC AUC: {valid_score}')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 7516023,
     "sourceId": 61542,
     "sourceType": "competition"
    },
    {
     "datasetId": 3945154,
     "sourceId": 6865136,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4300801,
     "sourceId": 7396904,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4300822,
     "sourceId": 7396931,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4351877,
     "sourceId": 7555434,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4352274,
     "sourceId": 7508268,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30635,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 94.956266,
   "end_time": "2024-02-04T22:28:54.696829",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-02-04T22:27:19.740563",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
